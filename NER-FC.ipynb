{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import utils\n",
    "import model.net as net\n",
    "from model.data_loader import DataLoader\n",
    "from evaluate import evaluate, f_score_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/coNLL/eng/'\n",
    "model_dir = 'experiments/coNLL/base_model/'\n",
    "# data_dir = 'data/kaggle/'\n",
    "# model_dir = 'experiments/kaggle/base_model/'\n",
    "path_glove = '../sequence_tagging/data/glove.6B/glove.6B.100d.txt'\n",
    "\n",
    "json_path = os.path.join(model_dir, 'params.json')\n",
    "params = utils.Params(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001,\n",
       " 'batch_size': 5,\n",
       " 'num_epochs': 15,\n",
       " 'lstm_hidden_dim': 100,\n",
       " 'embedding_dim': 100,\n",
       " 'save_summary_steps': 100,\n",
       " 'cuda': True,\n",
       " 'use_glove': True,\n",
       " 'dropout': 0.2,\n",
       " 'train_size': 14041,\n",
       " 'dev_size': 3250,\n",
       " 'test_size': 3453,\n",
       " 'vocab_size': 30291,\n",
       " 'number_of_tags': 8,\n",
       " 'pad_word': '<pad>',\n",
       " 'pad_tag': 'O',\n",
       " 'unk_word': 'UNK',\n",
       " 'val_size': 3250,\n",
       " 'pad_tag_ind': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use GPU if available\n",
    "params.cuda = torch.cuda.is_available()\n",
    "params.num_epochs = 15\n",
    "params.lstm_hidden_dim = 100\n",
    "params.embedding_dim = 100\n",
    "params.use_glove = True\n",
    "params.dropout = 0.2\n",
    "params.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041 14041\n",
      "3250 3250\n",
      "3453 3453\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_loader = DataLoader(data_dir, params, path_glove)\n",
    "data = data_loader.load_data(['train', 'val', 'test'])\n",
    "train_data = data['train']\n",
    "val_data = data['val']\n",
    "test_data = data['test']\n",
    "\n",
    "# specify the train and val dataset sizes\n",
    "params.train_size = train_data['size']\n",
    "params.val_size = val_data['size']\n",
    "params.test_size = test_data['size']\n",
    "\n",
    "params.pad_tag_ind = data_loader.tag_map[params.pad_tag]\n",
    "# data_loader.dataset_params.dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and optimizer\n",
    "model = net.Net(params, data_loader.embedding).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params.learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(model.parameters(), lr=params.learning_rate)\n",
    "# optimizer = optim.Adagrad(model.parameters(), lr=params.learning_rate)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=params.learning_rate/2)\n",
    "# optimizer = optim.Rprop(model.parameters(), lr=params.learning_rate)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=params.learning_rate, momentum=0.9) # nesterov=True\n",
    "# fetch loss function and metrics\n",
    "loss_fn = net.loss_fn\n",
    "metrics = net.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.defaults['lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logger\n",
    "utils.set_logger(os.path.join(model_dir, 'train.log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, data_iterator, metrics, params, num_steps):\n",
    "    \"\"\"Train the model on `num_steps` batches\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        optimizer: (torch.optim) optimizer for parameters of model\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        data_iterator: (generator) a generator that generates batches of data, labels and seq lengths \n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # summary for current training loop and a running average object for loss\n",
    "    summ = []\n",
    "    loss_avg = utils.RunningAverage()\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    t = trange(num_steps) \n",
    "    for i in t:\n",
    "        # fetch the next training batch\n",
    "        train_batch, labels_batch,_ = next(data_iterator)\n",
    "\n",
    "        # compute model output and loss\n",
    "        output_batch = model(train_batch)\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "        # clear previous gradients, compute gradients of all variables wrt loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # performs updates using calculated gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate summaries only once in a while\n",
    "        if i % params.save_summary_steps == 0:\n",
    "            # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "            output_batch = output_batch.data.cpu().numpy()\n",
    "            labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "            # compute all metrics on this batch\n",
    "            summary_batch = {metric:metrics[metric](output_batch, labels_batch, params) for metric in metrics}\n",
    "            summary_batch['loss'] = loss.item()\n",
    "            summ.append(summary_batch)\n",
    "            \n",
    "            # print('Evaluate called')\n",
    "            \n",
    "            \n",
    "\n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.item())\n",
    "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]} \n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
    "    logging.info(\"- Train metrics: \" + metrics_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 195.71it/s, loss=0.186]\n",
      "- Train metrics: accuracy: 0.928 ; loss: 0.227\n",
      "- Eval metrics : accuracy: 0.959 ; loss: 0.138 ; f1: 85.602\n",
      "- Found new best accuracy\n",
      "Epoch 2/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 197.97it/s, loss=0.092]\n",
      "- Train metrics: accuracy: 0.971 ; loss: 0.086\n",
      "- Eval metrics : accuracy: 0.971 ; loss: 0.098 ; f1: 89.658\n",
      "- Found new best accuracy\n",
      "Epoch 3/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 198.17it/s, loss=0.061]\n",
      "- Train metrics: accuracy: 0.982 ; loss: 0.059\n",
      "- Eval metrics : accuracy: 0.975 ; loss: 0.083 ; f1: 90.620\n",
      "- Found new best accuracy\n",
      "Epoch 4/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 197.84it/s, loss=0.044]\n",
      "- Train metrics: accuracy: 0.990 ; loss: 0.038\n",
      "- Eval metrics : accuracy: 0.976 ; loss: 0.082 ; f1: 91.341\n",
      "- Found new best accuracy\n",
      "Epoch 5/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 198.31it/s, loss=0.031]\n",
      "- Train metrics: accuracy: 0.990 ; loss: 0.027\n",
      "- Eval metrics : accuracy: 0.979 ; loss: 0.080 ; f1: 91.793\n",
      "- Found new best accuracy\n",
      "Epoch 6/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 197.86it/s, loss=0.023]\n",
      "- Train metrics: accuracy: 0.994 ; loss: 0.032\n",
      "- Eval metrics : accuracy: 0.979 ; loss: 0.080 ; f1: 91.786\n",
      "Epoch 7/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 197.97it/s, loss=0.015]\n",
      "- Train metrics: accuracy: 0.997 ; loss: 0.012\n",
      "- Eval metrics : accuracy: 0.978 ; loss: 0.085 ; f1: 91.371\n",
      "Epoch 8/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 197.72it/s, loss=0.010]\n",
      "- Train metrics: accuracy: 0.997 ; loss: 0.008\n",
      "- Eval metrics : accuracy: 0.979 ; loss: 0.086 ; f1: 91.644\n",
      "Epoch 9/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 198.03it/s, loss=0.007]\n",
      "- Train metrics: accuracy: 0.997 ; loss: 0.007\n",
      "- Eval metrics : accuracy: 0.978 ; loss: 0.095 ; f1: 91.187\n",
      "Epoch 10/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 197.88it/s, loss=0.005]\n",
      "- Train metrics: accuracy: 0.997 ; loss: 0.007\n",
      "- Eval metrics : accuracy: 0.976 ; loss: 0.104 ; f1: 90.694\n",
      "Epoch 11/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 197.78it/s, loss=0.003]\n",
      "- Train metrics: accuracy: 0.998 ; loss: 0.005\n",
      "- Eval metrics : accuracy: 0.976 ; loss: 0.107 ; f1: 91.033\n",
      "Epoch 12/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 197.77it/s, loss=0.002]\n",
      "- Train metrics: accuracy: 1.000 ; loss: 0.001\n",
      "- Eval metrics : accuracy: 0.977 ; loss: 0.113 ; f1: 91.289\n",
      "Epoch 13/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 197.82it/s, loss=0.002]\n",
      "- Train metrics: accuracy: 1.000 ; loss: 0.001\n",
      "- Eval metrics : accuracy: 0.977 ; loss: 0.122 ; f1: 90.731\n",
      "Epoch 14/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 197.75it/s, loss=0.001]\n",
      "- Train metrics: accuracy: 0.999 ; loss: 0.001\n",
      "- Eval metrics : accuracy: 0.979 ; loss: 0.126 ; f1: 91.713\n",
      "Epoch 15/15\n",
      "100%|██████████| 2808/2808 [00:14<00:00, 198.00it/s, loss=0.001]\n",
      "- Train metrics: accuracy: 1.000 ; loss: 0.001\n",
      "- Eval metrics : accuracy: 0.978 ; loss: 0.127 ; f1: 91.568\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(params.num_epochs):\n",
    "    # Run one epoch\n",
    "    logging.info(\"Epoch {}/{}\".format(epoch + 1, params.num_epochs))\n",
    "\n",
    "    # compute number of batches in one epoch (one full pass over the training set)\n",
    "    num_steps = (len(train_data['data']) + 1) // params.batch_size\n",
    "    train_data_iterator = data_loader.data_iterator(train_data, params, shuffle=True)\n",
    "    train(model, optimizer, loss_fn, train_data_iterator, metrics, params, num_steps)\n",
    "\n",
    "    # Evaluate for one epoch on validation set\n",
    "    num_steps = (params.val_size + 1) // params.batch_size\n",
    "    val_data_iterator = data_loader.data_iterator(val_data, params, shuffle=False)\n",
    "    val_metrics = evaluate(model, loss_fn, val_data, metrics, data_loader, params, num_steps)\n",
    "\n",
    "    # val_acc = val_metrics['accuracy']\n",
    "    val_acc = val_metrics['f1']\n",
    "    is_best = val_acc >= best_val_acc\n",
    "\n",
    "    # Save weights\n",
    "    utils.save_checkpoint({'epoch': epoch + 1,\n",
    "                           'state_dict': model.state_dict(),\n",
    "                           'optim_dict' : optimizer.state_dict()}, \n",
    "                           is_best=is_best,\n",
    "                           checkpoint=model_dir)\n",
    "\n",
    "    # If best_eval, best_save_path        \n",
    "    if is_best:\n",
    "        logging.info(\"- Found new best accuracy\")\n",
    "        best_val_acc = val_acc\n",
    "\n",
    "        # Save best val metrics in a json file in the model directory\n",
    "        best_json_path = os.path.join(model_dir, \"metrics_val_best_weights.json\")\n",
    "        utils.save_dict_to_json(val_metrics, best_json_path)\n",
    "\n",
    "    # Save latest val metrics in a json file in the model directory\n",
    "    last_json_path = os.path.join(model_dir, \"metrics_val_last_weights.json\")\n",
    "    utils.save_dict_to_json(val_metrics, last_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.53061224489795"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps = (params.val_size + 1) // params.batch_size\n",
    "f_score_simple(model, val_data, data_loader, params, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# model = net.Net(params).cuda() if params.cuda else net.Net(params)\n",
    "\n",
    "restore_file = 'best'\n",
    "# Reload weights from the saved file\n",
    "r = utils.load_checkpoint(os.path.join(model_dir, restore_file + '.pth.tar'), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "num_steps = (params.test_size + 1) // params.batch_size\n",
    "test_metrics = evaluate(model, loss_fn, test_data, metrics, data_loader, params, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
