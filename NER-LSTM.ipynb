{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER: BiLSTM-LSTM Model\n",
    "Use LSTM as the decoder. \n",
    "\n",
    "For the time being consider no batching. \n",
    "Later implement batching as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "\n",
    "import utils\n",
    "import model.net as net\n",
    "from model.data_loader import DataLoader\n",
    "from evaluate import evaluate, f_score_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001,\n",
       " 'batch_size': 5,\n",
       " 'num_epochs': 15,\n",
       " 'lstm_hidden_dim': 50,\n",
       " 'embedding_dim': 50,\n",
       " 'save_summary_steps': 100,\n",
       " 'cuda': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'data/coNLL/eng/'\n",
    "model_dir = 'experiments/coNLL/lstm_model/'\n",
    "# data_dir = 'data/kaggle/'\n",
    "# model_dir = 'experiments/kaggle/lstm_model/'\n",
    "json_path = os.path.join(model_dir, 'params.json')\n",
    "params = utils.Params(json_path)\n",
    "# use GPU if available\n",
    "params.cuda = torch.cuda.is_available()\n",
    "params.num_epochs = 15\n",
    "params.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041 14041\n",
      "3250 3250\n",
      "3453 3453\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_loader = DataLoader(data_dir, params)\n",
    "data = data_loader.load_data(['train', 'val', 'test'])\n",
    "train_data = data['train']\n",
    "val_data = data['val']\n",
    "test_data = data['test']\n",
    "\n",
    "# specify the train and val dataset sizes\n",
    "params.train_size = train_data['size']\n",
    "params.val_size = val_data['size']\n",
    "params.test_size = test_data['size']\n",
    "\n",
    "params.pad_tag_ind = data_loader.tag_map[params.pad_tag]\n",
    "params.batch_size = 1\n",
    "SOS_token = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        # the embedding takes as input the vocab_size and the embedding_dim\n",
    "        self.embedding = nn.Embedding(params.vocab_size, params.embedding_dim)\n",
    "\n",
    "        # the LSTM takes as input the size of its input (embedding_dim), its hidden size\n",
    "        # for more details on how to use it, check out the documentation\n",
    "        self.encoder = nn.GRU(params.embedding_dim, params.lstm_hidden_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, s):   \n",
    "        # apply the embedding layer that maps each token to its embedding\n",
    "        s = self.embedding(s)            # dim: seq_len x batch_size x embedding_dim\n",
    "\n",
    "        # run the LSTM along the sentences of length seq_len\n",
    "        output, hidden = self.encoder(s)    # dim: seq_len x batch_size x lstm_hidden_dim\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "        \n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = params.lstm_hidden_dim\n",
    "        self.tag_size = params.number_of_tags # SOS is represented as all zero vector\n",
    "        self.decoder = nn.GRU(self.tag_size + self.hidden_size, self.hidden_size, batch_first=True)\n",
    "        \n",
    "        # the fully connected layer transforms the output to give the final output layer\n",
    "        self.fc = nn.Linear(self.hidden_size, self.tag_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, prev_tag, hidden, encoder_output):\n",
    "        '''prev_tag: is a scalar\n",
    "           hidden: is the previous hidden vector: as we are now processing one sentence word by word\n",
    "           encoder_output: encoder's  corresponding output in the input sentence\n",
    "           \n",
    "           output: 1 x tag_size\n",
    "        '''\n",
    "        tag = torch.zeros(1, self.tag_size).cuda()\n",
    "        if prev_tag >= 0:\n",
    "            tag[0][prev_tag] = 1 # 1 hot encoding\n",
    "            \n",
    "        encoder_output = encoder_output.view(1, -1)\n",
    "        output = torch.cat((tag, encoder_output), dim=1)\n",
    "        output = output.unsqueeze(1)\n",
    "        \n",
    "        # apply one cell of GRU\n",
    "        output, hidden = self.decoder(output, hidden)  \n",
    "        \n",
    "        # apply the fully connected layer and obtain the output (before softmax) for each token\n",
    "        output = self.fc(output[0])                   # dim: batch_size*seq_len x num_tags\n",
    "\n",
    "        # apply log softmax on each token's output \n",
    "        output = F.log_softmax(output, dim=1)   # dim: batch_size*seq_len x num_tags\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningAverage():\n",
    "    \"\"\"A simple class that maintains the running average of a quantity\n",
    "    Example:\n",
    "    ```\n",
    "    loss_avg = RunningAverage()\n",
    "    loss_avg.update(2)\n",
    "    loss_avg.update(4)\n",
    "    loss_avg() = 3\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.total = 0\n",
    "\n",
    "    def update(self, val, step=1):\n",
    "        self.total += val\n",
    "        self.steps += step\n",
    "\n",
    "    def __call__(self):\n",
    "        if self.steps == 0:\n",
    "            # return float('nan')\n",
    "            return 0\n",
    "        else:\n",
    "            return self.total / float(self.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logger\n",
    "utils.set_logger(os.path.join(model_dir, 'train.log'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(data_iterator, encoder, decoder, encoder_optimizer, decoder_optimizer, num_steps):\n",
    "    \n",
    "    # set model to training mode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    # Running average object for loss, accuracy \n",
    "    loss_avg = RunningAverage()\n",
    "    acc_avg = RunningAverage()\n",
    "    other_ind = data_loader.tag_map['O']\n",
    "    recall = RunningAverage()\n",
    "    precision = RunningAverage()\n",
    "    \n",
    "    t = trange(num_steps) \n",
    "    \n",
    "    for i in t:\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        train_batch, labels_batch, _ = next(data_iterator) \n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(train_batch)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        loss = 0\n",
    "        prev_token = SOS_token # -1\n",
    "        predicted_tokens = torch.zeros_like(labels_batch)\n",
    "        \n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for di in range(labels_batch.shape[1]):\n",
    "                decoder_output, decoder_hidden = decoder(prev_token, decoder_hidden, encoder_outputs[:,di,:])\n",
    "                prev_token = labels_batch[:, di].item() # Teacher forcing\n",
    "                _, predicted_tokens[0][di] = torch.max(decoder_output.view(-1), dim=0)\n",
    "                loss += criterion(decoder_output, labels_batch[:, di])\n",
    "\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            for di in range(labels_batch.shape[1]):\n",
    "                decoder_output, decoder_hidden = decoder(prev_token, decoder_hidden, encoder_outputs[:,di,:])\n",
    "                topv, topi = torch.max(decoder_output.view(-1), dim=0)\n",
    "                prev_token = topi.item()\n",
    "                predicted_tokens[0][di] = topi\n",
    "                loss += criterion(decoder_output, labels_batch[:,di])\n",
    "        \n",
    "        # find accuracy of prediction\n",
    "        correct = (predicted_tokens == labels_batch).view(-1).cpu().numpy()\n",
    "        acc_avg.update(sum(correct), len(correct))\n",
    "        \n",
    "        # find accuracy (recall) for only named entities other than O\n",
    "        ne_labels = labels_batch.view(-1).cpu().numpy() != other_ind\n",
    "        recall.update(sum(correct & ne_labels), sum(ne_labels))\n",
    "        \n",
    "        # find precision of ne predictions\n",
    "        ne_preds = predicted_tokens.view(-1).cpu().numpy() != other_ind\n",
    "        precision.update(sum(correct & ne_preds), sum(ne_preds))\n",
    "        \n",
    "        # find f-score\n",
    "        if (recall() + precision()) == 0:\n",
    "            f_score = 0\n",
    "        else:\n",
    "            f_score = 2*recall()*precision() / (recall() + precision())\n",
    "        \n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.item())\n",
    "        \n",
    "        \n",
    "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()), acc='{:05.3f}'.format(acc_avg()), f1='{:05.3f}'.format(f_score))\n",
    "        \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_iterator, encoder, decoder, num_steps):\n",
    "    \n",
    "    print('Evaluating:')\n",
    "    # set model to eval mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # Running average object for loss, accuracy and ne_accuracy\n",
    "    # ne_accuracy: omit the 'O' tag for computing accuracy\n",
    "    loss_avg = RunningAverage()\n",
    "    acc_avg = RunningAverage()\n",
    "    other_ind = data_loader.tag_map['O']\n",
    "    recall = RunningAverage()\n",
    "    precision = RunningAverage()\n",
    "    \n",
    "    t = trange(num_steps) \n",
    "    \n",
    "    for i in t:\n",
    "\n",
    "        test_batch, labels_batch, _ = next(data_iterator) \n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(test_batch)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        loss = 0\n",
    "        prev_token = SOS_token # -1\n",
    "        predicted_tokens = torch.zeros_like(labels_batch)\n",
    "\n",
    "        for di in range(labels_batch.shape[1]):\n",
    "            decoder_output, decoder_hidden = decoder(prev_token, decoder_hidden, encoder_outputs[:,di,:])\n",
    "            topv, topi = torch.max(decoder_output.view(-1), dim=0)\n",
    "            prev_token = topi.item()\n",
    "            predicted_tokens[0][di] = topi\n",
    "            loss += criterion(decoder_output, labels_batch[:,di])\n",
    "        \n",
    "        # find accuracy of prediction\n",
    "        correct = (predicted_tokens == labels_batch).view(-1).cpu().numpy()\n",
    "        acc_avg.update(sum(correct), len(correct))\n",
    "        \n",
    "        # find accuracy (recall) for only named entities other than O\n",
    "        ne_labels = labels_batch.view(-1).cpu().numpy() != other_ind\n",
    "        recall.update(sum(correct & ne_labels), sum(ne_labels))\n",
    "        \n",
    "        # find precision of ne predictions\n",
    "        ne_preds = predicted_tokens.view(-1).cpu().numpy() != other_ind\n",
    "        precision.update(sum(correct & ne_preds), sum(ne_preds))\n",
    "        \n",
    "        # find f-score\n",
    "        if (recall() + precision()) == 0:\n",
    "            f_score = 0\n",
    "        else:\n",
    "            f_score = 2*recall()*precision() / (recall() + precision())\n",
    "        \n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.item())\n",
    "        \n",
    "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()), acc='{:05.3f}'.format(acc_avg()), f1='{:05.3f}'.format(f_score))\n",
    "    \n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and optimizer\n",
    "encoder1 = EncoderRNN(params).cuda()\n",
    "decoder1 = DecoderRNN(params).cuda()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder1.parameters(), lr=params.learning_rate, momentum=0.9)\n",
    "decoder_optimizer = optim.SGD(decoder1.parameters(), lr=params.learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint, extra=''):\n",
    "    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
    "    checkpoint + 'best.pth.tar'\n",
    "    Args:\n",
    "        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
    "        is_best: (bool) True if it is the best model seen till now\n",
    "        checkpoint: (string) folder where parameters are to be saved\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(checkpoint, extra + 'last.pth.tar')\n",
    "    if not os.path.exists(checkpoint):\n",
    "        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
    "        os.mkdir(checkpoint)\n",
    "    else:\n",
    "        print(\"Checkpoint Directory exists! \")\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, extra + 'best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 30%|██▉       | 4156/14041 [01:05<02:35, 63.75it/s, acc=0.840, f1=0.173, loss=8.363] "
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(params.num_epochs):\n",
    "    # Run one epoch\n",
    "    logging.info(\"Epoch {}/{}\".format(epoch + 1, params.num_epochs))\n",
    "\n",
    "    # compute number of batches in one epoch (one full pass over the training set)\n",
    "    # num_steps = params.train_size\n",
    "    train_data_iterator = data_loader.data_iterator(train_data, params, shuffle=True)\n",
    "    train(train_data_iterator, encoder1, decoder1, encoder_optimizer, decoder_optimizer, params.train_size)\n",
    "\n",
    "    # Evaluate for one epoch on validation set\n",
    "    # num_steps = params.val_size \n",
    "    val_data_iterator = data_loader.data_iterator(val_data, params, shuffle=False)\n",
    "    val_acc = evaluate(val_data_iterator, encoder1, decoder1, params.val_size)\n",
    "    val_metrics = {\"f1\": val_acc}\n",
    "    \n",
    "    is_best = val_acc >= best_val_acc\n",
    "\n",
    "    # Save weights\n",
    "    state_encoder = {'epoch': epoch + 1, 'state_dict': encoder1.state_dict(), 'optim_dict' : encoder_optimizer.state_dict()}\n",
    "    save_checkpoint(state_encoder, is_best=is_best, checkpoint=model_dir, extra='encoder_')\n",
    "    \n",
    "    state_decoder = {'epoch': epoch + 1, 'state_dict': decoder1.state_dict(), 'optim_dict' : decoder_optimizer.state_dict()}\n",
    "    save_checkpoint(state_decoder, is_best=is_best, checkpoint=model_dir, extra='decoder_')\n",
    "\n",
    "    # If best_eval, best_save_path        \n",
    "    if is_best:\n",
    "        logging.info(\"- Found new best accuracy\")\n",
    "        best_val_acc = val_acc\n",
    "\n",
    "        # Save best val metrics in a json file in the model directory\n",
    "        best_json_path = os.path.join(model_dir, \"f1_score_best_weights.json\")\n",
    "        utils.save_dict_to_json(val_metrics, best_json_path)\n",
    "\n",
    "    # Save latest val metrics in a json file in the model directory\n",
    "    last_json_path = os.path.join(model_dir, \"f1_score_last_weights.json\")\n",
    "    utils.save_dict_to_json(val_metrics, last_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
