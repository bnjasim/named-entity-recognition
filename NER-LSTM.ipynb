{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER: BiLSTM-LSTM Model\n",
    "Use LSTM as the decoder. \n",
    "\n",
    "For the time being consider no batching. \n",
    "Later implement batching as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "\n",
    "import utils\n",
    "from model.data_loader import DataLoader\n",
    "from evaluate import evaluate, f_score_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001,\n",
       " 'batch_size': 5,\n",
       " 'num_epochs': 15,\n",
       " 'lstm_hidden_dim': 100,\n",
       " 'embedding_dim': 100,\n",
       " 'save_summary_steps': 100,\n",
       " 'cuda': True,\n",
       " 'use_glove': True,\n",
       " 'dropout': 0.1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'data/coNLL/eng/'\n",
    "model_dir = 'experiments/coNLL/lstm_model/'\n",
    "# data_dir = 'data/kaggle/'\n",
    "# model_dir = 'experiments/kaggle/lstm_model/'\n",
    "path_glove = '../sequence_tagging/data/glove.6B/glove.6B.100d.txt'\n",
    "\n",
    "json_path = os.path.join(model_dir, 'params.json')\n",
    "params = utils.Params(json_path)\n",
    "# use GPU if available\n",
    "params.cuda = torch.cuda.is_available()\n",
    "params.use_glove = True\n",
    "params.dropout = 0.1\n",
    "params.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041 14041\n",
      "3250 3250\n",
      "3453 3453\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_loader = DataLoader(data_dir, params, path_glove)\n",
    "data = data_loader.load_data(['train', 'val', 'test'])\n",
    "train_data = data['train']\n",
    "val_data = data['val']\n",
    "test_data = data['test']\n",
    "\n",
    "# specify the train and val dataset sizes\n",
    "params.train_size = train_data['size']\n",
    "params.val_size = val_data['size']\n",
    "params.test_size = test_data['size']\n",
    "\n",
    "params.pad_tag_ind = data_loader.tag_map[params.pad_tag]\n",
    "params.batch_size = 1\n",
    "SOS_token = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, params, embedding):\n",
    "        '''embedding is the glove embedding loaded in the data_loader.py'''\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        # the embedding takes as input the vocab_size and the embedding_dim\n",
    "        self.embedding = nn.Embedding(params.vocab_size, params.embedding_dim)\n",
    "        # copy pretrained embedding\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding))\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # the LSTM takes as input the size of its input (embedding_dim), its hidden size\n",
    "        # for more details on how to use it, check out the documentation\n",
    "        self.encoder = nn.GRU(params.embedding_dim, params.lstm_hidden_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, s):   \n",
    "        # apply the embedding layer that maps each token to its embedding\n",
    "        s = self.embedding(s)            # dim: seq_len x batch_size x embedding_dim\n",
    "        s = self.dropout(s)\n",
    "\n",
    "        # run the LSTM along the sentences of length seq_len\n",
    "        output, hidden = self.encoder(s)    # dim: seq_len x batch_size x lstm_hidden_dim\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "        \n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = params.lstm_hidden_dim\n",
    "        self.tag_size = params.number_of_tags # SOS is represented as all zero vector\n",
    "        self.decoder = nn.GRU(self.tag_size + self.hidden_size, self.hidden_size, batch_first=True)\n",
    "        \n",
    "        # the fully connected layer transforms the output to give the final output layer\n",
    "        self.fc = nn.Linear(self.hidden_size, self.tag_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, prev_tag, hidden, encoder_output):\n",
    "        '''prev_tag: is a scalar\n",
    "           hidden: is the previous hidden vector: as we are now processing one sentence word by word\n",
    "           encoder_output: encoder's  corresponding output in the input sentence\n",
    "           \n",
    "           output: 1 x tag_size\n",
    "        '''\n",
    "        tag = torch.zeros(1, self.tag_size).cuda()\n",
    "        if prev_tag >= 0:\n",
    "            tag[0][prev_tag] = 1 # 1 hot encoding\n",
    "            \n",
    "        encoder_output = encoder_output.view(1, -1)\n",
    "        output = torch.cat((tag, encoder_output), dim=1)\n",
    "        output = output.unsqueeze(1)\n",
    "        \n",
    "        # apply one cell of GRU\n",
    "        output, hidden = self.decoder(output, hidden)  \n",
    "        \n",
    "        # apply the fully connected layer and obtain the output (before softmax) for each token\n",
    "        output = self.fc(output[0])                   # dim: batch_size*seq_len x num_tags\n",
    "\n",
    "        # apply log softmax on each token's output \n",
    "        output = F.log_softmax(output, dim=1)   # dim: batch_size*seq_len x num_tags\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logger\n",
    "utils.set_logger(os.path.join(model_dir, 'train.log'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(data_iterator, encoder, decoder, encoder_optimizer, decoder_optimizer, num_steps):\n",
    "    \n",
    "    # set model to training mode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    # Running average object for loss, accuracy \n",
    "    loss_avg = utils.RunningAverage()\n",
    "    acc_avg = utils.RunningAverage()\n",
    "    other_ind = data_loader.tag_map['O']\n",
    "    recall = utils.RunningAverage()\n",
    "    precision = utils.RunningAverage()\n",
    "    \n",
    "    t = trange(num_steps) \n",
    "    \n",
    "    for i in t:\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        train_batch, labels_batch, _ = next(data_iterator) \n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(train_batch)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        loss = 0\n",
    "        prev_token = SOS_token # -1\n",
    "        predicted_tokens = torch.zeros_like(labels_batch)\n",
    "        \n",
    "        use_teacher_forcing = False #True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for di in range(labels_batch.shape[1]):\n",
    "                decoder_output, decoder_hidden = decoder(prev_token, decoder_hidden, encoder_outputs[:,di,:])\n",
    "                prev_token = labels_batch[:, di].item() # Teacher forcing\n",
    "                _, predicted_tokens[0][di] = torch.max(decoder_output.view(-1), dim=0)\n",
    "                loss += criterion(decoder_output, labels_batch[:, di])\n",
    "\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            for di in range(labels_batch.shape[1]):\n",
    "                decoder_output, decoder_hidden = decoder(prev_token, decoder_hidden, encoder_outputs[:,di,:])\n",
    "                topv, topi = torch.max(decoder_output.view(-1), dim=0)\n",
    "                prev_token = topi.item()\n",
    "                predicted_tokens[0][di] = topi\n",
    "                loss += criterion(decoder_output, labels_batch[:,di])\n",
    "        \n",
    "        # find accuracy of prediction\n",
    "        correct = (predicted_tokens == labels_batch).view(-1).cpu().numpy()\n",
    "        acc_avg.update(sum(correct), len(correct))\n",
    "        \n",
    "        # find accuracy (recall) for only named entities other than O\n",
    "        ne_labels = labels_batch.view(-1).cpu().numpy() != other_ind\n",
    "        recall.update(sum(correct & ne_labels), sum(ne_labels))\n",
    "        \n",
    "        # find precision of ne predictions\n",
    "        ne_preds = predicted_tokens.view(-1).cpu().numpy() != other_ind\n",
    "        precision.update(sum(correct & ne_preds), sum(ne_preds))\n",
    "        \n",
    "        # find f-score\n",
    "        if (recall() + precision()) == 0:\n",
    "            f_score = 0\n",
    "        else:\n",
    "            f_score = 2*recall()*precision() / (recall() + precision())\n",
    "        \n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.item())\n",
    "        \n",
    "        \n",
    "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()), acc='{:05.3f}'.format(acc_avg()), f1='{:05.3f}'.format(f_score))\n",
    "        \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_iterator, encoder, decoder, num_steps):\n",
    "    \n",
    "    logging.info('Evaluating:')\n",
    "    # set model to eval mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # Running average object for loss, accuracy and ne_accuracy\n",
    "    # ne_accuracy: omit the 'O' tag for computing accuracy\n",
    "    loss_avg = utils.RunningAverage()\n",
    "    acc_avg = utils.RunningAverage()\n",
    "    other_ind = data_loader.tag_map['O']\n",
    "    recall = utils.RunningAverage()\n",
    "    precision = utils.RunningAverage()\n",
    "    \n",
    "    t = trange(num_steps) \n",
    "    \n",
    "    for i in t:\n",
    "\n",
    "        test_batch, labels_batch, _ = next(data_iterator) \n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(test_batch)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        loss = 0\n",
    "        prev_token = SOS_token # -1\n",
    "        predicted_tokens = torch.zeros_like(labels_batch)\n",
    "\n",
    "        for di in range(labels_batch.shape[1]):\n",
    "            decoder_output, decoder_hidden = decoder(prev_token, decoder_hidden, encoder_outputs[:,di,:])\n",
    "            topv, topi = torch.max(decoder_output.view(-1), dim=0)\n",
    "            prev_token = topi.item()\n",
    "            predicted_tokens[0][di] = topi\n",
    "            loss += criterion(decoder_output, labels_batch[:,di])\n",
    "        \n",
    "        # find accuracy of prediction\n",
    "        correct = (predicted_tokens == labels_batch).view(-1).cpu().numpy()\n",
    "        acc_avg.update(sum(correct), len(correct))\n",
    "        \n",
    "        # find accuracy (recall) for only named entities other than O\n",
    "        ne_labels = labels_batch.view(-1).cpu().numpy() != other_ind\n",
    "        recall.update(sum(correct & ne_labels), sum(ne_labels))\n",
    "        \n",
    "        # find precision of ne predictions\n",
    "        ne_preds = predicted_tokens.view(-1).cpu().numpy() != other_ind\n",
    "        precision.update(sum(correct & ne_preds), sum(ne_preds))\n",
    "        \n",
    "        # find f-score\n",
    "        if (recall() + precision()) == 0:\n",
    "            f_score = 0\n",
    "        else:\n",
    "            f_score = 2*recall()*precision() / (recall() + precision())\n",
    "        \n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.item())\n",
    "        \n",
    "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()), acc='{:05.3f}'.format(acc_avg()), f1='{:05.3f}'.format(f_score))\n",
    "    \n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and optimizer\n",
    "encoder1 = EncoderRNN(params, data_loader.embedding).cuda()\n",
    "decoder1 = DecoderRNN(params).cuda()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#encoder_optimizer = optim.SGD(encoder1.parameters(), lr=params.learning_rate, momentum=0.9)\n",
    "#decoder_optimizer = optim.SGD(decoder1.parameters(), lr=params.learning_rate, momentum=0.9)\n",
    "encoder_optimizer = optim.Adam(encoder1.parameters(), lr=params.learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder1.parameters(), lr=params.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100%|██████████| 14041/14041 [08:00<00:00, 29.22it/s, acc=0.956, f1=0.826, loss=2.109]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [01:05<00:00, 49.37it/s, acc=0.968, f1=0.872, loss=1.650]\n",
      "- Found new best accuracy\n",
      "Epoch 2/15\n",
      "100%|██████████| 14041/14041 [08:04<00:00, 28.99it/s, acc=0.982, f1=0.923, loss=0.845]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [01:07<00:00, 48.04it/s, acc=0.972, f1=0.888, loss=1.534]\n",
      "- Found new best accuracy\n",
      "Epoch 3/15\n",
      "100%|██████████| 14041/14041 [08:02<00:00, 29.09it/s, acc=0.989, f1=0.952, loss=0.510]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [01:06<00:00, 49.23it/s, acc=0.971, f1=0.883, loss=1.658]\n",
      "Epoch 4/15\n",
      "100%|██████████| 14041/14041 [08:02<00:00, 29.12it/s, acc=0.993, f1=0.968, loss=0.342]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [01:06<00:00, 48.99it/s, acc=0.971, f1=0.884, loss=1.805]\n",
      "Epoch 5/15\n",
      "100%|██████████| 14041/14041 [06:25<00:00, 36.42it/s, acc=0.995, f1=0.978, loss=0.233]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:34<00:00, 92.93it/s, acc=0.973, f1=0.890, loss=1.880] \n",
      "- Found new best accuracy\n",
      "Epoch 6/15\n",
      "100%|██████████| 14041/14041 [04:17<00:00, 54.51it/s, acc=0.996, f1=0.982, loss=0.190]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:35<00:00, 92.61it/s, acc=0.972, f1=0.883, loss=2.048] \n",
      "Epoch 7/15\n",
      "100%|██████████| 14041/14041 [04:17<00:00, 54.58it/s, acc=0.996, f1=0.984, loss=0.165]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:35<00:00, 91.69it/s, acc=0.973, f1=0.886, loss=2.020] \n",
      "Epoch 8/15\n",
      "100%|██████████| 14041/14041 [04:18<00:00, 54.39it/s, acc=0.997, f1=0.986, loss=0.139]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:35<00:00, 92.83it/s, acc=0.973, f1=0.885, loss=2.099] \n",
      "Epoch 9/15\n",
      "100%|██████████| 14041/14041 [04:17<00:00, 54.45it/s, acc=0.997, f1=0.988, loss=0.127]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:35<00:00, 91.59it/s, acc=0.973, f1=0.886, loss=2.140]\n",
      "Epoch 10/15\n",
      "100%|██████████| 14041/14041 [04:18<00:00, 54.31it/s, acc=0.997, f1=0.988, loss=0.124]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:35<00:00, 92.31it/s, acc=0.973, f1=0.888, loss=2.286]\n",
      "Epoch 11/15\n",
      "100%|██████████| 14041/14041 [04:18<00:00, 54.23it/s, acc=0.998, f1=0.990, loss=0.103]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:35<00:00, 91.48it/s, acc=0.970, f1=0.874, loss=2.487] \n",
      "Epoch 12/15\n",
      "100%|██████████| 14041/14041 [04:18<00:00, 54.35it/s, acc=0.998, f1=0.990, loss=0.103]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:35<00:00, 92.58it/s, acc=0.971, f1=0.883, loss=2.409] \n",
      "Epoch 13/15\n",
      "100%|██████████| 14041/14041 [04:18<00:00, 54.38it/s, acc=0.998, f1=0.990, loss=0.096]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:35<00:00, 92.74it/s, acc=0.971, f1=0.882, loss=2.539] \n",
      "Epoch 14/15\n",
      "100%|██████████| 14041/14041 [04:19<00:00, 54.11it/s, acc=0.998, f1=0.991, loss=0.094]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:35<00:00, 91.99it/s, acc=0.971, f1=0.881, loss=2.489]\n",
      "Epoch 15/15\n",
      "100%|██████████| 14041/14041 [04:18<00:00, 54.23it/s, acc=0.998, f1=0.991, loss=0.097]\n",
      "Evaluating:\n",
      "100%|██████████| 3250/3250 [00:35<00:00, 91.23it/s, acc=0.971, f1=0.881, loss=2.561]\n"
     ]
    }
   ],
   "source": [
    "# params.num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(params.num_epochs):\n",
    "    # Run one epoch\n",
    "    logging.info(\"Epoch {}/{}\".format(epoch + 1, params.num_epochs))\n",
    "\n",
    "    # compute number of batches in one epoch (one full pass over the training set)\n",
    "    # num_steps = params.train_size\n",
    "    train_data_iterator = data_loader.data_iterator(train_data, params, shuffle=True)\n",
    "    train(train_data_iterator, encoder1, decoder1, encoder_optimizer, decoder_optimizer, params.train_size)\n",
    "\n",
    "    # Evaluate for one epoch on validation set\n",
    "    # num_steps = params.val_size \n",
    "    val_data_iterator = data_loader.data_iterator(val_data, params, shuffle=False)\n",
    "    val_acc = evaluate(val_data_iterator, encoder1, decoder1, params.val_size)\n",
    "    val_metrics = {\"f1\": val_acc}\n",
    "    \n",
    "    is_best = val_acc >= best_val_acc\n",
    "\n",
    "    # Save weights\n",
    "    state_encoder = {'epoch': epoch + 1, 'state_dict': encoder1.state_dict(), 'optim_dict' : encoder_optimizer.state_dict()}\n",
    "    utils.save_checkpoint(state_encoder, is_best=is_best, checkpoint=model_dir, extra='encoder_')\n",
    "    \n",
    "    state_decoder = {'epoch': epoch + 1, 'state_dict': decoder1.state_dict(), 'optim_dict' : decoder_optimizer.state_dict()}\n",
    "    utils.save_checkpoint(state_decoder, is_best=is_best, checkpoint=model_dir, extra='decoder_')\n",
    "\n",
    "    # If best_eval, best_save_path        \n",
    "    if is_best:\n",
    "        logging.info(\"- Found new best accuracy\")\n",
    "        best_val_acc = val_acc\n",
    "\n",
    "        # Save best val metrics in a json file in the model directory\n",
    "        best_json_path = os.path.join(model_dir, \"f1_score_best_weights.json\")\n",
    "        utils.save_dict_to_json(val_metrics, best_json_path)\n",
    "\n",
    "    # Save latest val metrics in a json file in the model directory\n",
    "    last_json_path = os.path.join(model_dir, \"f1_score_last_weights.json\")\n",
    "    utils.save_dict_to_json(val_metrics, last_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:\n",
      "100%|██████████| 3453/3453 [00:33<00:00, 103.53it/s, acc=0.963, f1=0.851, loss=2.464]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8511112486844549"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_iterator = data_loader.data_iterator(test_data, params, shuffle=False)\n",
    "evaluate(test_data_iterator, encoder1, decoder1, params.test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_file = 'encoder_best'\n",
    "# Reload weights from the saved file\n",
    "r = utils.load_checkpoint(os.path.join(model_dir, restore_file + '.pth.tar'), encoder1)\n",
    "\n",
    "restore_file = 'decoder_best'\n",
    "# Reload weights from the saved file\n",
    "r = utils.load_checkpoint(os.path.join(model_dir, restore_file + '.pth.tar'), decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
